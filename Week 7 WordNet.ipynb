{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10fb6dcf-e509-4307-a967-d84ce012762c",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">WordNet & WSD - Tutorial</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d29f74-ded0-4e01-895f-e30b97b57936",
   "metadata": {},
   "source": [
    "* WordNet synset names use a precise format e.g., **bank.n.01**:\n",
    "    * bank → **The lemma name** (the word itself).\n",
    "    * n → **Part of speech (POS)**: n = noun, v = verb, a = adjective, r = adverb.\n",
    "    * 01 → **The sense number** of that word (because a word may have multiple meanings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b03934c7-5c2b-4ca6-8132-3f7204cf99f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bank.n.01') : sloping land (especially the slope beside a body of water)\n",
      "Synset('depository_financial_institution.n.01') : a financial institution that accepts deposits and channels the money into lending activities\n",
      "Synset('bank.n.03') : a long ridge or pile\n",
      "Synset('bank.n.04') : an arrangement of similar objects in a row or in tiers\n",
      "Synset('bank.n.05') : a supply or stock held in reserve for future use (especially in emergencies)\n",
      "Synset('bank.n.06') : the funds held by a gambling house or the dealer in some gambling games\n",
      "Synset('bank.n.07') : a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "Synset('savings_bank.n.02') : a container (usually with a slot in the top) for keeping money at home\n",
      "Synset('bank.n.09') : a building in which the business of banking transacted\n",
      "Synset('bank.n.10') : a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
      "Synset('bank.v.01') : tip laterally\n",
      "Synset('bank.v.02') : enclose with a bank\n",
      "Synset('bank.v.03') : do business with a bank or keep an account at a bank\n",
      "Synset('bank.v.04') : act as the banker in a game or in gambling\n",
      "Synset('bank.v.05') : be in the banking business\n",
      "Synset('deposit.v.02') : put into a bank account\n",
      "Synset('bank.v.07') : cover with ashes so to control the rate of burning\n",
      "Synset('trust.v.01') : have confidence or faith in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Khor Kean\n",
      "[nltk_data]     Teng\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# Download wordnet for the first time\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Get all synsets for \"bank\"\n",
    "for syn in wn.synsets(\"bank\"):\n",
    "    print(syn, \":\", syn.definition())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "754e3acd-3795-4e03-b120-03bbd3fe4508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bank.n.01') : sloping land (especially the slope beside a body of water)\n",
      "Synset('depository_financial_institution.n.01') : a financial institution that accepts deposits and channels the money into lending activities\n",
      "Synset('bank.n.03') : a long ridge or pile\n",
      "Synset('bank.n.04') : an arrangement of similar objects in a row or in tiers\n",
      "Synset('bank.n.05') : a supply or stock held in reserve for future use (especially in emergencies)\n",
      "Synset('bank.n.06') : the funds held by a gambling house or the dealer in some gambling games\n",
      "Synset('bank.n.07') : a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "Synset('savings_bank.n.02') : a container (usually with a slot in the top) for keeping money at home\n",
      "Synset('bank.n.09') : a building in which the business of banking transacted\n",
      "Synset('bank.n.10') : a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n"
     ]
    }
   ],
   "source": [
    "# Get all noun senses of 'bank'\n",
    "bank_synsets = wn.synsets('bank', pos=wn.NOUN)\n",
    "for syn in bank_synsets:\n",
    "    print(syn, \":\", syn.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dbebe7-545b-4900-90be-c19f70d15fa5",
   "metadata": {},
   "source": [
    "## Taxonomy-Based Similarity\n",
    "* It’s a semantic similarity metric between **two synsets (word senses) within the same part of speech** (noun-noun, verb-verb, etc.).\n",
    "* The **shortest path between two synsets in WordNet based on their hypernym/hyponym tree**.\n",
    "* **path similarity Formula:** 1/(shortest path length + 1)\n",
    "* Range:\n",
    "  * 1.0 → identical synsets (maximum similarity)\n",
    "  * Close to 0 → distant or unrelated synsets\n",
    "  * None → no path between the synsets (usually if they are different parts of speech, e.g., noun vs verb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f761e3d-6947-4397-94ca-7e333191f9f6",
   "metadata": {},
   "source": [
    "## Hypernym path = IS-A path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d394dbaf-c2cd-454d-a13e-3acc78e6b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entity.n.01', 'physical_entity.n.01', 'object.n.01', 'whole.n.02', 'living_thing.n.01', 'organism.n.01', 'animal.n.01', 'domestic_animal.n.01', 'dog.n.01']\n",
      "['entity.n.01', 'physical_entity.n.01', 'object.n.01', 'whole.n.02', 'living_thing.n.01', 'organism.n.01', 'animal.n.01', 'chordate.n.01', 'vertebrate.n.01', 'mammal.n.01', 'placental.n.01', 'carnivore.n.01', 'canine.n.02', 'dog.n.01']\n"
     ]
    }
   ],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "for path in dog.hypernym_paths():\n",
    "    print([syn.name() for syn in path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5297302e-664b-43b4-b329-bfb48bc0016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entity.n.01', 'physical_entity.n.01', 'object.n.01', 'whole.n.02', 'living_thing.n.01', 'organism.n.01', 'animal.n.01', 'chordate.n.01', 'vertebrate.n.01', 'mammal.n.01', 'placental.n.01', 'carnivore.n.01', 'feline.n.01', 'cat.n.01']\n"
     ]
    }
   ],
   "source": [
    "dog = wn.synset('cat.n.01')\n",
    "for path in dog.hypernym_paths():\n",
    "    print([syn.name() for syn in path])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2bccb3-3f6a-46dc-b377-b95ec9ca6eca",
   "metadata": {},
   "source": [
    "## Path between Synsets\n",
    "* In WordNet, all nouns (and verbs) are organized in a tree.\n",
    "    * **Synsets** (concepts) are nodes.\n",
    "    * **Hypernym/Hyponym** relations are edges.\n",
    "* Path distance = the number of edges between two synsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef4ae7de-1ca4-486b-b20b-d05eab1d531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest path length: 4\n",
      "Path Similarity: 0.2\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "syn1 = wn.synset('dog.n.01')\n",
    "syn2 = wn.synset('cat.n.01')\n",
    "\n",
    "# Get all possible paths to the root for both synsets\n",
    "paths1 = syn1.hypernym_paths()\n",
    "paths2 = syn2.hypernym_paths()\n",
    "\n",
    "# Find the shortest path between syn1 and syn2\n",
    "shortest_distance = syn1.shortest_path_distance(syn2)\n",
    "print(\"Shortest path length:\", shortest_distance)\n",
    "\n",
    "similarity = syn1.path_similarity(syn2)\n",
    "print(\"Path Similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44931360-6a4b-4118-bbe3-00a7687fc815",
   "metadata": {},
   "source": [
    "* The Lowest Common Ancestor (LCA) is **carnivore**, and we count edges:\n",
    "    * dog → canine → **carnivore** (2 steps)\n",
    "    * cat → feline → **carnivore** (2 steps)\n",
    "    * Shortest path = 2 + 2 = 4.\n",
    "    * Similarity = 1 / (4 + 1) = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7ee19d-b3a3-4a4a-be15-7d79ff44256c",
   "metadata": {},
   "source": [
    "## Semantic Similarity Comparison using WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "984d6d5e-1028-47b4-a88a-03c6f70e0bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First vs Final similarity: 0.08333333333333333\n",
      "Hair vs Comb similarity: 0.1111111111111111\n",
      "Doctor vs Hospital similarity: 0.07142857142857142\n",
      "Doctor vs Nurse similarity: 0.25\n",
      "Doctor-Nurse is stronger.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# 1. First vs Final\n",
    "first = wn.synset('first.n.01')\n",
    "final = wn.synset('final.n.01')\n",
    "similarity_first_final = first.path_similarity(final)\n",
    "\n",
    "# 2. Hair vs Comb\n",
    "hair = wn.synset('hair.n.01')\n",
    "comb = wn.synset('comb.n.01')\n",
    "similarity_hair_comb = hair.path_similarity(comb)\n",
    "\n",
    "# 3. Doctor vs Hospital & Doctor vs Nurse\n",
    "doctor = wn.synset('doctor.n.01')\n",
    "hospital = wn.synset('hospital.n.01')\n",
    "nurse = wn.synset('nurse.n.01')\n",
    "\n",
    "similarity_doc_hosp = doctor.path_similarity(hospital)\n",
    "similarity_doc_nurse = doctor.path_similarity(nurse)\n",
    "\n",
    "# Print results\n",
    "print(f\"First vs Final similarity: {similarity_first_final}\")\n",
    "print(f\"Hair vs Comb similarity: {similarity_hair_comb}\")\n",
    "print(f\"Doctor vs Hospital similarity: {similarity_doc_hosp}\")\n",
    "print(f\"Doctor vs Nurse similarity: {similarity_doc_nurse}\")\n",
    "\n",
    "# Which is stronger\n",
    "if similarity_doc_hosp > similarity_doc_nurse:\n",
    "    print(\"Doctor-Hospital is stronger.\")\n",
    "elif similarity_doc_hosp < similarity_doc_nurse:\n",
    "    print(\"Doctor-Nurse is stronger.\")\n",
    "else:\n",
    "    print(\"Both have equal similarity.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ff97fa-15f2-49ec-a27e-77a9737e2b27",
   "metadata": {},
   "source": [
    "## Word Sense Disambiguation with WordNet\n",
    "* We will disambiguate the word 'bank' in two contexts using NLTK's Lesk.\n",
    "* nltk.wsd.lesk → NLTK’s implementation of **the Simplified Lesk Algorithm**.\n",
    "* Predicts the best matching sense **based on gloss overlap** between the sentence context and the synset definitions.\n",
    "* No fancy NLP tricks (no stemming, no semantic similarity)—just raw word overlap.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ca8116e-1f79-46a7-a85f-6ab71588d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a0e0f4c-f0e4-4193-8315-2b5ac8191dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 context: She conducts her lending activities through a bank.\n",
      "Predicted sense: depository_financial_institution.n.01\n",
      "Definition: a financial institution that accepts deposits and channels the money into lending activities\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Financial context\n",
    "sentence1 = \"She conducts her lending activities through a bank.\"\n",
    "tokens1 = word_tokenize(sentence1)\n",
    "\n",
    "sense = lesk(tokens1, 'bank', 'n')\n",
    "print(\"Sentence 1 context:\", sentence1)\n",
    "print(\"Predicted sense:\", sense.name())\n",
    "print(\"Definition:\", sense.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d66e0921-919c-4489-aac5-02dd331b3ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 2 context: The fisherman sat patiently on the grassy bank beside the water.\n",
      "Predicted sense: bank.n.01\n",
      "Definition: sloping land (especially the slope beside a body of water)\n"
     ]
    }
   ],
   "source": [
    "# Example 2: River context\n",
    "sentence2 = \"The fisherman sat patiently on the grassy bank beside the water.\"\n",
    "tokens = word_tokenize(sentence2)\n",
    "\n",
    "sense = lesk(tokens, 'bank', 'n')\n",
    "print(\"Sentence 2 context:\", sentence2)\n",
    "print(\"Predicted sense:\", sense.name())\n",
    "print(\"Definition:\", sense.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8561bb-e5db-4366-86e5-3c1225ef7e03",
   "metadata": {},
   "source": [
    "## WSD Using Contextual Embeddings (WordNet + BERT)\n",
    "Instead of relying on word overlap (like Lesk), we now:\n",
    "\n",
    "* Retrieve glosses (definitions) of each possible WordNet sense of the target word (bank).\n",
    "* Use a pre-trained language model like BERT to **compute sentence embeddings**:\n",
    "    * One for the context sentence.\n",
    "    * One for each gloss.\n",
    "* Measure similarity (cosine similarity) between the context embedding and each gloss embedding.\n",
    "* Pick the sense with the highest similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bdb3eba-3fa9-43fd-bdcd-d26bcf4729ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a7e6508f5a42e682f5a4896fa6daf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Khor Kean Teng\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Khor Kean Teng\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7c9fb47cf74580b433fbc4da44b361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ec9fb142ac42398d26fa841994e386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d033dee6f7488499e7dde403459888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689523fd11b1400690be0590c17e1e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e943b0b00b43a7834aa2ce2589e10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6c6cc343384184940af0780b8e70c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad0084e02744436ba265093a35751a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa3351733d242679580f5d1f0041c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bbdc6a503c4477853b1a7efa4c44c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507df978ca844a898786dcacf4a05a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sense: bank.n.01\n",
      "Gloss: sloping land (especially the slope beside a body of water)\n",
      "Similarity: -0.0125\n",
      "\n",
      "Sense: depository_financial_institution.n.01\n",
      "Gloss: a financial institution that accepts deposits and channels the money into lending activities\n",
      "Similarity: 0.3637\n",
      "\n",
      "Sense: bank.n.03\n",
      "Gloss: a long ridge or pile\n",
      "Similarity: 0.0037\n",
      "\n",
      "Sense: bank.n.04\n",
      "Gloss: an arrangement of similar objects in a row or in tiers\n",
      "Similarity: -0.0993\n",
      "\n",
      "Sense: bank.n.05\n",
      "Gloss: a supply or stock held in reserve for future use (especially in emergencies)\n",
      "Similarity: 0.1110\n",
      "\n",
      "Sense: bank.n.06\n",
      "Gloss: the funds held by a gambling house or the dealer in some gambling games\n",
      "Similarity: 0.3313\n",
      "\n",
      "Sense: bank.n.07\n",
      "Gloss: a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "Similarity: -0.0231\n",
      "\n",
      "Sense: savings_bank.n.02\n",
      "Gloss: a container (usually with a slot in the top) for keeping money at home\n",
      "Similarity: 0.2544\n",
      "\n",
      "Sense: bank.n.09\n",
      "Gloss: a building in which the business of banking transacted\n",
      "Similarity: 0.3400\n",
      "\n",
      "Sense: bank.n.10\n",
      "Gloss: a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
      "Similarity: 0.0199\n",
      "\n",
      "Best Sense: depository_financial_institution.n.01\n",
      "Definition: a financial institution that accepts deposits and channels the money into lending activities\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Initialize the sentence embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # BERT-based model designed for efficiency\n",
    "\n",
    "# Context sentence\n",
    "sentence = \"She went to the bank to open a savings account.\"\n",
    "\n",
    "# Get all noun senses of 'bank'\n",
    "bank_synsets = wn.synsets('bank', pos=wn.NOUN)\n",
    "\n",
    "# Embed the sentence\n",
    "sentence_emb = model.encode(sentence, convert_to_tensor=True)\n",
    "\n",
    "best_score = -1\n",
    "best_sense = None\n",
    "\n",
    "# Compare with each sense's gloss\n",
    "for syn in bank_synsets:\n",
    "    gloss = syn.definition()\n",
    "    gloss_emb = model.encode(gloss, convert_to_tensor=True)\n",
    "    similarity = util.pytorch_cos_sim(sentence_emb, gloss_emb).item()\n",
    "    print(f\"Sense: {syn.name()}\\nGloss: {gloss}\\nSimilarity: {similarity:.4f}\\n\")\n",
    "    \n",
    "    if similarity > best_score:\n",
    "        best_score = similarity\n",
    "        best_sense = syn\n",
    "\n",
    "# Final result\n",
    "print(\"Best Sense:\", best_sense.name())\n",
    "print(\"Definition:\", best_sense.definition())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
