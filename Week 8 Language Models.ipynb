{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d066f5b-b375-4ad4-90b3-8431d3f9e10e",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Language Models - Tutorial</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e00a66-139f-4ca2-9166-34c111889e72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install dependencies (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f212bcfb-82b1-4b53-b7a5-2a454b9eb746",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install transformers nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac71fcf-71f1-487a-9e21-34b512655195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install \"numpy<2.0.0\" --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c00ae2-626c-463a-a3cd-de72dea99b5a",
   "metadata": {},
   "source": [
    "## N-Grams Using Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed40be-fe6d-44bd-85a0-e79a37db3b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter # used for frequency counting\n",
    "\n",
    "# Download Brown corpus if not already downloaded\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f77cd-c80f-40bb-9255-893079c0f29a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9c9ff-4402-46ee-9a15-e54d82281701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = brown.words() # list of all tokens including punctuations\n",
    "sents = brown.sents()\n",
    "paras = brown.paras()\n",
    "categories = brown.categories()\n",
    "\n",
    "print(f\"Number of words: {len(words)}\")\n",
    "print(f\"Number of sentences: {len(sents)}\")\n",
    "print(f\"Number of paragraphs: {len(paras)}\")\n",
    "print(f\"Number of categories: {len(categories)}\")\n",
    "print(f\"Categories: {categories}\")\n",
    "print(f\"Vocabulary size: {len(set([w.lower() for w in words]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2facd5b-2e0a-4144-9727-d4a3e0d7ee3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Load and preprocess Brown corpus (convert to lowercase)\n",
    "tokens = [word.lower() for word in words] # include punctuations  \n",
    "clean_tokens = [w for w in tokens if w not in string.punctuation]\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceae6d5-28ad-47be-8420-638402ef44ee",
   "metadata": {},
   "source": [
    "### Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6ebce8-3b44-4ea5-918d-9c9812173877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unigrams = list(ngrams(tokens, 1))\n",
    "unigram_freq = Counter(unigrams)\n",
    "\n",
    "print(\"Top 10 Unigrams:\")\n",
    "for word, freq in unigram_freq.most_common(10):\n",
    "    print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc697e7-79b9-4a26-9298-2389d08b07b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(unigram_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeeb854-8073-4c45-b11e-4984efd45f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unigram_freq = Counter(clean_tokens)\n",
    "\n",
    "# Show top 10 most common unigrams (no punctuation)\n",
    "print(\"Top 10 Unigrams (Punctuation Removed):\")\n",
    "for word, freq in unigram_freq.most_common(10):\n",
    "    print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9677d38b-b16a-4b8e-b8ab-8e3b1d4d6029",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4084df2-896f-4cb8-958d-a3981ef6056d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bigrams = list(ngrams(clean_tokens, 2))\n",
    "bigram_freq = Counter(bigrams)\n",
    "\n",
    "print(\"Top 10 Bigrams:\")\n",
    "for pair, freq in bigram_freq.most_common(10):\n",
    "    print(f\"{pair}: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9401791d-cad4-4e33-8ae0-22f6673a6abd",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2c416-8927-47c9-853d-6df02a2b5c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trigrams = list(ngrams(clean_tokens, 3))\n",
    "trigram_freq = Counter(trigrams)\n",
    "\n",
    "print(\"Top 10 Trigrams:\")\n",
    "for triplet, freq in trigram_freq.most_common(10):\n",
    "    print(f\"{triplet}: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd054d1-807c-411d-ba6c-d93ece7a5267",
   "metadata": {},
   "source": [
    "## Next Word Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb9c1e-c47a-4a09-b050-683912093e13",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Input Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de7f40-edc3-4f46-93f4-9b6ee0fc86e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "partial_sentence = \"The doctor said the patient might have to\"\n",
    "print(\"Input:\", partial_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b07e59-58b6-4830-841d-f54b9c9c212e",
   "metadata": {},
   "source": [
    "### Statistical Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff68c42-f82f-44e1-a0b0-1c0dddbf3cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk import FreqDist # NLTK specific frequency counting\n",
    "from nltk import bigrams, trigrams, ngrams\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Lowercase words from Brown corpus\n",
    "tokens = [w.lower() for w in brown.words()]\n",
    "clean_tokens = [w for w in tokens if w not in string.punctuation]\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abea15e-2904-4578-9cb8-61f1c40b6099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build frequency distributions\n",
    "bi_freq = FreqDist(bigrams(clean_tokens)) # a dictionary (bigram, count)\n",
    "tri_freq = FreqDist(trigrams(clean_tokens)) # a dictionary (trigram, count)\n",
    "\n",
    "print(f\"Bigram frequency distribution sample: {bi_freq.most_common(5)}\")\n",
    "print(f\"Trigram frequency distribution sample: {tri_freq.most_common(5)}\")\n",
    "\n",
    "# Get previous words of input\n",
    "input_text = partial_sentence.lower().split()\n",
    "\n",
    "last_input = tuple(input_text[-1:])\n",
    "last_bigram = tuple(input_text[-2:])\n",
    "\n",
    "print(\"==\"*50)\n",
    "print(\"Input: %s____\"%partial_sentence)\n",
    "print(f\"Last input for Bigram: {last_input}\")\n",
    "print(f\"Last bigram for Trigram: {last_bigram}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25df69-547f-4043-9642-22474d8d2cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all trigrams that start with \"as well\"\n",
    "item = [k for k,v in tri_freq.items() if k[:-1] == tuple(['as', 'well'])]\n",
    "print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4323560-9763-4be9-afcc-7ca755c851e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 5 most likely next words that follow a given context\n",
    "def get_most_likely_next_word(freq_dist, context):\n",
    "    # the following line produces a dictionary of {next_word: count} for all matching n-grams\n",
    "    candidates = {k[-1]: v for k, v in freq_dist.items() if k[:-1] == context}\n",
    "    # Sort candidates by frequency (descending)\n",
    "    sorted_candidates = sorted(candidates.items(), key=lambda x: -x[1])\n",
    "    # Return top 5\n",
    "    return sorted_candidates[:5]\n",
    "\n",
    "bigram_predictions = get_most_likely_next_word(bi_freq, last_input)\n",
    "print(\"Bigram prediction:\")\n",
    "print(bigram_predictions)\n",
    "\n",
    "trigram_predictions = get_most_likely_next_word(tri_freq, last_bigram)\n",
    "print(\"\\nTrigram prediction:\")\n",
    "print(trigram_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a392c278-99d5-41f4-95fc-1ca96436b6fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Input Sentence Bigram Predictions:\")\n",
    "for word, count in bigram_predictions:\n",
    "    sentence = f\"{partial_sentence} {word}\"\n",
    "    print(f\"{sentence}  [{count}]\")\n",
    "\n",
    "print(\"\\nInput Sentence Trigram Predictions:\")\n",
    "for word, count in trigram_predictions:\n",
    "    sentence = f\"{partial_sentence} {word}\"\n",
    "    print(f\"{sentence}  [{count}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4859c32e-ae41-409c-b8a3-08e66fc11f49",
   "metadata": {},
   "source": [
    "## Transformer-based Language Model (Hugging Face GPT-2)\n",
    "* GPT-2 is pretrained on massive web text (WebText corpus) in an unsupervised, causal language modeling fashion (i.e., predicting the next token given all previous ones).\n",
    "* GPT-2 generates one token at a time, feeding each new token back into itself until.\n",
    "* GPT-2 is **pretrained but not fine-tuned** for a specific task.\n",
    "* You control how many words/tokens it outputs using **max_new_tokens**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e857f564-b2bc-4c14-b0e7-8c07c49c16a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "# Load text generation pipeline with GPT-2\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "set_seed(42) # random seed for reproducibility\n",
    "\n",
    "prompt = \"The doctor said the patient might have to\" # → 8 tokens\n",
    "# generate a sequence of tokens (words, punctuation, etc.) up to 15 tokens total (including the prompt length)\n",
    "outputs = generator(prompt, max_length=15, num_return_sequences=3, max_new_tokens=1) # increase max_new_tokens\n",
    "\n",
    "print(\"\\nGPT-2 Predictions:\")\n",
    "for i, output in enumerate(outputs):\n",
    "    print(f\"{i+1}: {output['generated_text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3539a245-50f8-4afd-84c0-72866d881857",
   "metadata": {},
   "source": [
    "### Final Notes:\n",
    "* GPT-3 is not on Hugging Face since it is a proprietary model developed by OpenAI.\n",
    "* How about Llama?\n",
    "* Access to Llama models is restricted and **requires accepting the license on HF**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b3b563-23b1-4712-a076-dd9ba090433b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
